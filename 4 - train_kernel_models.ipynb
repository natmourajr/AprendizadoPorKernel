{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db1e8ed",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61f352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import Models\n",
    "from AuxiliarFunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673cc4f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e184bb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_id</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_files_path</th>\n",
       "      <th>processed_file_folder</th>\n",
       "      <th>processed_file_path</th>\n",
       "      <th>cv_alg</th>\n",
       "      <th>cv_folds</th>\n",
       "      <th>cv_path</th>\n",
       "      <th>preproc_alg</th>\n",
       "      <th>pipeline_path</th>\n",
       "      <th>scaler_alg</th>\n",
       "      <th>train_data_path</th>\n",
       "      <th>train_trgt_path</th>\n",
       "      <th>model_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>Toy Data Classification with 10 StratifiedKFolds</td>\n",
       "      <td>data/raw</td>\n",
       "      <td>data</td>\n",
       "      <td>data/-8662869763806803064_processed_data.csv</td>\n",
       "      <td>StratifiedKFolds</td>\n",
       "      <td>10</td>\n",
       "      <td>data/indexes</td>\n",
       "      <td>Não implementado para a aplicação!!!</td>\n",
       "      <td>data/pipelines</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>data/-8662869763806803064_train_data.csv</td>\n",
       "      <td>data/-8662869763806803064_trgt_data.csv</td>\n",
       "      <td>data/models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               hash_id                                             label  \\\n",
       "0 -8662869763806803064  Toy Data Classification with 10 StratifiedKFolds   \n",
       "\n",
       "  raw_files_path processed_file_folder  \\\n",
       "0       data/raw                  data   \n",
       "\n",
       "                            processed_file_path            cv_alg  cv_folds  \\\n",
       "0  data/-8662869763806803064_processed_data.csv  StratifiedKFolds        10   \n",
       "\n",
       "        cv_path                           preproc_alg   pipeline_path  \\\n",
       "0  data/indexes  Não implementado para a aplicação!!!  data/pipelines   \n",
       "\n",
       "       scaler_alg                           train_data_path  \\\n",
       "0  StandardScaler  data/-8662869763806803064_train_data.csv   \n",
       "\n",
       "                           train_trgt_path   model_path  \n",
       "0  data/-8662869763806803064_trgt_data.csv  data/models  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file_path = 'data/config.csv'\n",
    "df_config = pd.read_csv(config_file_path)\n",
    "train_id = 0\n",
    "\n",
    "df_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a5ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(df_config['train_data_path'][train_id])\n",
    "df_trgt = pd.read_csv(df_config['train_trgt_path'][train_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9bfaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target\n",
       "0          1\n",
       "1          1\n",
       "2          0\n",
       "3          0\n",
       "4          1\n",
       "...      ...\n",
       "9995       1\n",
       "9996       0\n",
       "9997       0\n",
       "9998       0\n",
       "9999       1\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trgt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf290a",
   "metadata": {},
   "source": [
    "# Processo de Treinamento de um modelo simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a750ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Kernel Training\n",
      "Processing Training for polynomial kernel\n",
      "Processing Training for logistic loss\n",
      "Training 1 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_0_fold_model_polynomial_kernel_logistic_loss.pkl\n",
      "Training 2 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_1_fold_model_polynomial_kernel_logistic_loss.pkl\n",
      "Training 3 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_2_fold_model_polynomial_kernel_logistic_loss.pkl\n",
      "Training 4 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_3_fold_model_polynomial_kernel_logistic_loss.pkl\n",
      "Training 5 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_4_fold_model_polynomial_kernel_logistic_loss.pkl\n",
      "Training 6 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_5_fold_model_polynomial_kernel_logistic_loss.pkl\n",
      "Training 7 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_6_fold_model_polynomial_kernel_logistic_loss.pkl\n",
      "Training 8 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_7_fold_model_polynomial_kernel_logistic_loss.pkl\n",
      "Training 9 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_8_fold_model_polynomial_kernel_logistic_loss.pkl\n",
      "Training 10 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_9_fold_model_polynomial_kernel_logistic_loss.pkl\n",
      "Processing Training for soft_margin loss\n",
      "Training 1 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_0_fold_model_polynomial_kernel_soft_margin_loss.pkl\n",
      "Training 2 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_1_fold_model_polynomial_kernel_soft_margin_loss.pkl\n",
      "Training 3 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_2_fold_model_polynomial_kernel_soft_margin_loss.pkl\n",
      "Training 4 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_3_fold_model_polynomial_kernel_soft_margin_loss.pkl\n",
      "Training 5 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_4_fold_model_polynomial_kernel_soft_margin_loss.pkl\n",
      "Training 6 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_5_fold_model_polynomial_kernel_soft_margin_loss.pkl\n",
      "Training 7 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_6_fold_model_polynomial_kernel_soft_margin_loss.pkl\n",
      "Training 8 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_7_fold_model_polynomial_kernel_soft_margin_loss.pkl\n",
      "Training 9 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_8_fold_model_polynomial_kernel_soft_margin_loss.pkl\n",
      "Training 10 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_9_fold_model_polynomial_kernel_soft_margin_loss.pkl\n",
      "Processing Training for quadratic_soft_margin loss\n",
      "Training 1 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_0_fold_model_polynomial_kernel_quadratic_soft_margin_loss.pkl\n",
      "Training 2 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_1_fold_model_polynomial_kernel_quadratic_soft_margin_loss.pkl\n",
      "Training 3 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_2_fold_model_polynomial_kernel_quadratic_soft_margin_loss.pkl\n",
      "Training 4 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_3_fold_model_polynomial_kernel_quadratic_soft_margin_loss.pkl\n",
      "Training 5 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_4_fold_model_polynomial_kernel_quadratic_soft_margin_loss.pkl\n",
      "Training 6 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_5_fold_model_polynomial_kernel_quadratic_soft_margin_loss.pkl\n",
      "Training 7 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_6_fold_model_polynomial_kernel_quadratic_soft_margin_loss.pkl\n",
      "Training 8 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_7_fold_model_polynomial_kernel_quadratic_soft_margin_loss.pkl\n",
      "Training 9 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_8_fold_model_polynomial_kernel_quadratic_soft_margin_loss.pkl\n",
      "Training 10 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_9_fold_model_polynomial_kernel_quadratic_soft_margin_loss.pkl\n",
      "Processing Training for squared_loss loss\n",
      "Training 1 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_0_fold_model_polynomial_kernel_squared_loss_loss.pkl\n",
      "Training 2 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_1_fold_model_polynomial_kernel_squared_loss_loss.pkl\n",
      "Training 3 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_2_fold_model_polynomial_kernel_squared_loss_loss.pkl\n",
      "Training 4 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_3_fold_model_polynomial_kernel_squared_loss_loss.pkl\n",
      "Training 5 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_4_fold_model_polynomial_kernel_squared_loss_loss.pkl\n",
      "Training 6 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_5_fold_model_polynomial_kernel_squared_loss_loss.pkl\n",
      "Training 7 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_6_fold_model_polynomial_kernel_squared_loss_loss.pkl\n",
      "Training 8 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_7_fold_model_polynomial_kernel_squared_loss_loss.pkl\n",
      "Training 9 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_8_fold_model_polynomial_kernel_squared_loss_loss.pkl\n",
      "Training 10 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_9_fold_model_polynomial_kernel_squared_loss_loss.pkl\n",
      "Processing Training for e-insensitive loss\n",
      "Training 1 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_0_fold_model_polynomial_kernel_e-insensitive_loss.pkl\n",
      "Training 2 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_1_fold_model_polynomial_kernel_e-insensitive_loss.pkl\n",
      "Training 3 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_2_fold_model_polynomial_kernel_e-insensitive_loss.pkl\n",
      "Training 4 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_3_fold_model_polynomial_kernel_e-insensitive_loss.pkl\n",
      "Training 5 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_4_fold_model_polynomial_kernel_e-insensitive_loss.pkl\n",
      "Training 6 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_5_fold_model_polynomial_kernel_e-insensitive_loss.pkl\n",
      "Training 7 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_6_fold_model_polynomial_kernel_e-insensitive_loss.pkl\n",
      "Training 8 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_7_fold_model_polynomial_kernel_e-insensitive_loss.pkl\n",
      "Training 9 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_8_fold_model_polynomial_kernel_e-insensitive_loss.pkl\n",
      "Training 10 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_9_fold_model_polynomial_kernel_e-insensitive_loss.pkl\n",
      "Processing Training for huber loss\n",
      "Training 1 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_0_fold_model_polynomial_kernel_huber_loss.pkl\n",
      "Training 2 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_1_fold_model_polynomial_kernel_huber_loss.pkl\n",
      "Training 3 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_2_fold_model_polynomial_kernel_huber_loss.pkl\n",
      "Training 4 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_3_fold_model_polynomial_kernel_huber_loss.pkl\n",
      "Training 5 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_4_fold_model_polynomial_kernel_huber_loss.pkl\n",
      "Training 6 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_5_fold_model_polynomial_kernel_huber_loss.pkl\n",
      "Training 7 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_6_fold_model_polynomial_kernel_huber_loss.pkl\n",
      "Training 8 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_7_fold_model_polynomial_kernel_huber_loss.pkl\n",
      "Training 9 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_8_fold_model_polynomial_kernel_huber_loss.pkl\n",
      "Training 10 fold of 10 folds\n",
      "\n",
      "\n",
      "Reading Cross-validation indexes\n",
      "Done\n",
      "Reading Pipeline Object\n",
      "Done\n",
      "Training for model\n",
      "Model is in data/models/-8662869763806803064_Kernel_9_fold_model_polynomial_kernel_huber_loss.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import time\n",
    "import copy\n",
    "import importlib\n",
    "importlib.reload(Models)\n",
    "\n",
    "model_type = 'Kernel'\n",
    "\n",
    "n_folds =  df_config['cv_folds'][train_id]\n",
    "cv_path = df_config['cv_path'][train_id]\n",
    "pipe_path = df_config['pipeline_path'][train_id]\n",
    "model_path = df_config['model_path'][train_id]\n",
    "\n",
    "print('Processing Kernel Training')\n",
    "\n",
    "kernels = ['polynomial']\n",
    "losses = ['logistic', 'soft_margin','quadratic_soft_margin','squared_loss','e-insensitive','huber']\n",
    "\n",
    "if os.path.exists(os.path.join(model_path,'%s_%s_train_record.csv'%(df_config['hash_id'][train_id], model_type))):\n",
    "\ttrain_record = pd.read_csv(os.path.join(model_path,'%s_%s_train_record.csv'%(df_config['hash_id'][train_id], model_type)))\n",
    "else:\n",
    "\ttrain_record = None\n",
    "\n",
    "for kernel in kernels:\n",
    "\tprint('Processing Training for %s kernel'%(kernel))\n",
    "\tfor loss in losses:\n",
    "\t\tprint('Processing Training for %s loss'%(loss))\n",
    "\t\tfor ifold in range(n_folds):\n",
    "\n",
    "\t\t\tprint('Training %i fold of %i folds\\n\\n'%(ifold+1, n_folds))\n",
    "\n",
    "\t\t\tprint('Reading Cross-validation indexes')\n",
    "\n",
    "\t\t\tcv_name = '%s_%s_CV_fold_%i_of_%i_cv_indexes.pkl'%(df_config['hash_id'][train_id],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdf_config['cv_alg'][train_id],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tifold, n_folds)\n",
    "\t\t\tprint('Done')\n",
    "\t\t\tprint('Reading Pipeline Object')\n",
    "\t\t\twith open(os.path.join(cv_path,cv_name),'rb') as file_handler:\n",
    "\t\t\t\t[trn_idx,val_idx] = pickle.load(file_handler)\n",
    "\n",
    "\t\t\tpipe_name ='%s_%s_CV_fold_%i_of_%i_pipe.pkl'%(df_config['hash_id'][train_id],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdf_config['cv_alg'][train_id],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tifold, n_folds)\n",
    "\t\t\twith open(os.path.join(pipe_path,pipe_name),'rb') as file_handler:\n",
    "\t\t\t\tpipe = joblib.load(file_handler)\n",
    "\n",
    "\t\t\tprint('Done')\n",
    "\n",
    "\t\t\ttrn_data = pipe.transform(df_data)\n",
    "\t\t\ttrn_trgt = df_trgt.values # tf.keras.utils.to_categorical(dev_target, num_classes=len(np.unique(dev_target)))\n",
    "\n",
    "\t\t\tprint('Training for model')\n",
    "\t\t\tmodel_name = '%s_%s_%i_fold_model_%s_kernel_%s_loss.pkl'%(df_config['hash_id'][train_id],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmodel_type, ifold, kernel, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tloss)\n",
    "\n",
    "\t\t\tif os.path.exists(os.path.join(model_path, model_name)):\n",
    "\t\t\t\tprint('Model is in %s'%(os.path.join(model_path, model_name)))\n",
    "\t\t\t\t\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint('No Model \\n\\n')\n",
    "\n",
    "\t\t\t\tmodel = Models.KernelClassifier(kernel=kernel,\n",
    "                                                      loss=loss,\n",
    "                                                      verbose=False)\n",
    "\t\t\t\tstart_time = time.time()\n",
    "\t\t\t\tmodel.fit(trn_data, trn_trgt, trn_id=trn_idx, val_id=val_idx, random_state=0,)\n",
    "\t\t\t\tend_time = time.time() # in seconds\n",
    "\n",
    "\t\t\t\tpredictions = model.predict(trn_data)\n",
    "\t\t\t\tdf_predict = pd.DataFrame(data=np.concatenate((trn_trgt, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpredictions),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\taxis=1), \n",
    "\t\t\t\t\t\t\t\t\t\tcolumns=['target', 'model_output'])\n",
    "\t\t\t\tprediction_name = copy.copy(model_name)\n",
    "\t\t\t\tprediction_name = prediction_name.replace('.pkl','_prediction_file.csv')\n",
    "\t\t\t\tdf_predict.to_csv(os.path.join(model_path, prediction_name),index=False)\n",
    "\t\t\t\n",
    "\t\t\t\tmodel.save(os.path.join(model_path, model_name))\n",
    "\t\t\t\t\n",
    "\t\t\t\tacc = Models.acc_score(df_predict.loc[val_idx,'target'],\n",
    "\t\t\t\t\t\t\t\t\tdf_predict.loc[val_idx,'model_output'])\n",
    "\t\t\t\tsens = Models.sensitivity_score(df_predict.loc[val_idx,'target'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tdf_predict.loc[val_idx,'model_output'])\n",
    "\t\t\t\tspec = Models.specificity_score(df_predict.loc[val_idx,'target'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tdf_predict.loc[val_idx,'model_output'])\n",
    "\t\t\t\tsp = Models.sp_index(df_predict.loc[val_idx,'target'],\n",
    "\t\t\t\t\t\t\t\t\tdf_predict.loc[val_idx,'model_output'])\n",
    "\t\t\t\tauc = Models.auc_score(df_predict.loc[val_idx,'target'],\n",
    "\t\t\t\t\t\t\t\t\tdf_predict.loc[val_idx,'model_output'])\n",
    "\t\t\t\t\n",
    "\t\t\t\tdict_train_record = {\n",
    "\t\t\t\t\t'hash_id':[df_config['hash_id'][train_id]],'fold':[ifold],\n",
    "\t\t\t\t\t'prediction_file':[prediction_name], 'kernel':[kernel],\n",
    "\t\t\t\t\t'loss':[loss], 'Acc':[acc],\n",
    "\t\t\t\t\t'Sens':[sens],'Spec':[spec],'SP':[sp], 'AUC':[auc],\n",
    "\t\t\t\t\t'Time':[end_time-start_time]\n",
    "\t\t\t\t}\n",
    "\t\t\t\tif train_record is None:\n",
    "\t\t\t\t\ttrain_record = pd.DataFrame(data=dict_train_record)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttrain_record = pd.concat([train_record,pd.DataFrame(data=dict_train_record)],axis=0, ignore_index=True)\n",
    "train_record.to_csv(os.path.join(model_path,'%s_%s_train_record.csv'%(df_config['hash_id'][train_id], model_type)),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56087812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>prediction_file</th>\n",
       "      <th>kernel</th>\n",
       "      <th>loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Spec</th>\n",
       "      <th>SP</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>0</td>\n",
       "      <td>-8662869763806803064_Kernel_0_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.792415</td>\n",
       "      <td>0.897796</td>\n",
       "      <td>0.712814</td>\n",
       "      <td>0.845105</td>\n",
       "      <td>2.070694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>1</td>\n",
       "      <td>-8662869763806803064_Kernel_1_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.707811</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>2.155312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>2</td>\n",
       "      <td>-8662869763806803064_Kernel_2_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.713660</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>2.155366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>3</td>\n",
       "      <td>-8662869763806803064_Kernel_3_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.733344</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>2.106785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>4</td>\n",
       "      <td>-8662869763806803064_Kernel_4_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>2.117187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>5</td>\n",
       "      <td>-8662869763806803064_Kernel_5_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.691424</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>2.006963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>6</td>\n",
       "      <td>-8662869763806803064_Kernel_6_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.674224</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>2.315056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>7</td>\n",
       "      <td>-8662869763806803064_Kernel_7_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.681025</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>2.139889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>8</td>\n",
       "      <td>-8662869763806803064_Kernel_8_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.718592</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>2.125958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>9</td>\n",
       "      <td>-8662869763806803064_Kernel_9_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.741891</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>2.132304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>0</td>\n",
       "      <td>-8662869763806803064_Kernel_0_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.794411</td>\n",
       "      <td>0.905812</td>\n",
       "      <td>0.721136</td>\n",
       "      <td>0.850111</td>\n",
       "      <td>0.552664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>1</td>\n",
       "      <td>-8662869763806803064_Kernel_1_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.733436</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>0.596144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>2</td>\n",
       "      <td>-8662869763806803064_Kernel_2_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.718862</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.589568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>3</td>\n",
       "      <td>-8662869763806803064_Kernel_3_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.740560</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.603745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>4</td>\n",
       "      <td>-8662869763806803064_Kernel_4_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.717144</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.558259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>5</td>\n",
       "      <td>-8662869763806803064_Kernel_5_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.704878</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.615575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>6</td>\n",
       "      <td>-8662869763806803064_Kernel_6_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.774000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.690540</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.650401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>7</td>\n",
       "      <td>-8662869763806803064_Kernel_7_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.694756</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.629031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>8</td>\n",
       "      <td>-8662869763806803064_Kernel_8_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.734028</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>0.596041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>9</td>\n",
       "      <td>-8662869763806803064_Kernel_9_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.750764</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.620196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>0</td>\n",
       "      <td>-8662869763806803064_Kernel_0_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>quadratic_soft_margin</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.768463</td>\n",
       "      <td>0.907816</td>\n",
       "      <td>0.700046</td>\n",
       "      <td>0.838139</td>\n",
       "      <td>0.614571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>1</td>\n",
       "      <td>-8662869763806803064_Kernel_1_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>quadratic_soft_margin</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.703675</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.707176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>2</td>\n",
       "      <td>-8662869763806803064_Kernel_2_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>quadratic_soft_margin</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.702996</td>\n",
       "      <td>0.839000</td>\n",
       "      <td>0.616575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>3</td>\n",
       "      <td>-8662869763806803064_Kernel_3_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>quadratic_soft_margin</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.720816</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.744768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>4</td>\n",
       "      <td>-8662869763806803064_Kernel_4_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>quadratic_soft_margin</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.703160</td>\n",
       "      <td>0.839000</td>\n",
       "      <td>0.684523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>5</td>\n",
       "      <td>-8662869763806803064_Kernel_5_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>quadratic_soft_margin</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.684231</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>0.629297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>6</td>\n",
       "      <td>-8662869763806803064_Kernel_6_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>quadratic_soft_margin</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.663259</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.626423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>7</td>\n",
       "      <td>-8662869763806803064_Kernel_7_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>quadratic_soft_margin</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.673882</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.670126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>8</td>\n",
       "      <td>-8662869763806803064_Kernel_8_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>quadratic_soft_margin</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.711453</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.717402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>9</td>\n",
       "      <td>-8662869763806803064_Kernel_9_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>quadratic_soft_margin</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.916000</td>\n",
       "      <td>0.736255</td>\n",
       "      <td>0.859000</td>\n",
       "      <td>0.730824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>0</td>\n",
       "      <td>-8662869763806803064_Kernel_0_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.752495</td>\n",
       "      <td>0.911824</td>\n",
       "      <td>0.689309</td>\n",
       "      <td>0.832159</td>\n",
       "      <td>0.196233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>1</td>\n",
       "      <td>-8662869763806803064_Kernel_1_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.697751</td>\n",
       "      <td>0.837000</td>\n",
       "      <td>0.200484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>2</td>\n",
       "      <td>-8662869763806803064_Kernel_2_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.687841</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.195464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>3</td>\n",
       "      <td>-8662869763806803064_Kernel_3_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.696580</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.194976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>4</td>\n",
       "      <td>-8662869763806803064_Kernel_4_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.675923</td>\n",
       "      <td>0.823000</td>\n",
       "      <td>0.203062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>5</td>\n",
       "      <td>-8662869763806803064_Kernel_5_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.671656</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0.191463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>6</td>\n",
       "      <td>-8662869763806803064_Kernel_6_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.659059</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.189217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>7</td>\n",
       "      <td>-8662869763806803064_Kernel_7_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.669803</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.198853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>8</td>\n",
       "      <td>-8662869763806803064_Kernel_8_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.774000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.682523</td>\n",
       "      <td>0.827000</td>\n",
       "      <td>0.189952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>9</td>\n",
       "      <td>-8662869763806803064_Kernel_9_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.774000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.714740</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.187324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>0</td>\n",
       "      <td>-8662869763806803064_Kernel_0_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>e-insensitive</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.798403</td>\n",
       "      <td>0.883768</td>\n",
       "      <td>0.706513</td>\n",
       "      <td>0.841085</td>\n",
       "      <td>1.351387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>1</td>\n",
       "      <td>-8662869763806803064_Kernel_1_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>e-insensitive</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.711367</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>1.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>2</td>\n",
       "      <td>-8662869763806803064_Kernel_2_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>e-insensitive</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.712048</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>1.416930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>3</td>\n",
       "      <td>-8662869763806803064_Kernel_3_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>e-insensitive</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.720436</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>1.397757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>4</td>\n",
       "      <td>-8662869763806803064_Kernel_4_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>e-insensitive</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.707100</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>1.438147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>5</td>\n",
       "      <td>-8662869763806803064_Kernel_5_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>e-insensitive</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.691774</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>1.368179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>6</td>\n",
       "      <td>-8662869763806803064_Kernel_6_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>e-insensitive</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.681123</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>1.316453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>7</td>\n",
       "      <td>-8662869763806803064_Kernel_7_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>e-insensitive</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.681554</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>1.348065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>8</td>\n",
       "      <td>-8662869763806803064_Kernel_8_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>e-insensitive</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.698558</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>1.288076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>9</td>\n",
       "      <td>-8662869763806803064_Kernel_9_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>e-insensitive</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.725326</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>1.282007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>0</td>\n",
       "      <td>-8662869763806803064_Kernel_0_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.754491</td>\n",
       "      <td>0.907816</td>\n",
       "      <td>0.687871</td>\n",
       "      <td>0.831153</td>\n",
       "      <td>0.663391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>1</td>\n",
       "      <td>-8662869763806803064_Kernel_1_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.696299</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.643139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>2</td>\n",
       "      <td>-8662869763806803064_Kernel_2_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.681217</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.639191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>3</td>\n",
       "      <td>-8662869763806803064_Kernel_3_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.703549</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.543670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>4</td>\n",
       "      <td>-8662869763806803064_Kernel_4_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.689456</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>0.634383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>5</td>\n",
       "      <td>-8662869763806803064_Kernel_5_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.677292</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.647208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>6</td>\n",
       "      <td>-8662869763806803064_Kernel_6_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.666075</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.640726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>7</td>\n",
       "      <td>-8662869763806803064_Kernel_7_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.758000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.678377</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.620359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>8</td>\n",
       "      <td>-8662869763806803064_Kernel_8_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.699163</td>\n",
       "      <td>0.837000</td>\n",
       "      <td>0.638821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-8662869763806803064</td>\n",
       "      <td>9</td>\n",
       "      <td>-8662869763806803064_Kernel_9_fold_model_polyn...</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.741120</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.635642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                hash_id  fold  \\\n",
       "0  -8662869763806803064     0   \n",
       "1  -8662869763806803064     1   \n",
       "2  -8662869763806803064     2   \n",
       "3  -8662869763806803064     3   \n",
       "4  -8662869763806803064     4   \n",
       "5  -8662869763806803064     5   \n",
       "6  -8662869763806803064     6   \n",
       "7  -8662869763806803064     7   \n",
       "8  -8662869763806803064     8   \n",
       "9  -8662869763806803064     9   \n",
       "10 -8662869763806803064     0   \n",
       "11 -8662869763806803064     1   \n",
       "12 -8662869763806803064     2   \n",
       "13 -8662869763806803064     3   \n",
       "14 -8662869763806803064     4   \n",
       "15 -8662869763806803064     5   \n",
       "16 -8662869763806803064     6   \n",
       "17 -8662869763806803064     7   \n",
       "18 -8662869763806803064     8   \n",
       "19 -8662869763806803064     9   \n",
       "20 -8662869763806803064     0   \n",
       "21 -8662869763806803064     1   \n",
       "22 -8662869763806803064     2   \n",
       "23 -8662869763806803064     3   \n",
       "24 -8662869763806803064     4   \n",
       "25 -8662869763806803064     5   \n",
       "26 -8662869763806803064     6   \n",
       "27 -8662869763806803064     7   \n",
       "28 -8662869763806803064     8   \n",
       "29 -8662869763806803064     9   \n",
       "30 -8662869763806803064     0   \n",
       "31 -8662869763806803064     1   \n",
       "32 -8662869763806803064     2   \n",
       "33 -8662869763806803064     3   \n",
       "34 -8662869763806803064     4   \n",
       "35 -8662869763806803064     5   \n",
       "36 -8662869763806803064     6   \n",
       "37 -8662869763806803064     7   \n",
       "38 -8662869763806803064     8   \n",
       "39 -8662869763806803064     9   \n",
       "40 -8662869763806803064     0   \n",
       "41 -8662869763806803064     1   \n",
       "42 -8662869763806803064     2   \n",
       "43 -8662869763806803064     3   \n",
       "44 -8662869763806803064     4   \n",
       "45 -8662869763806803064     5   \n",
       "46 -8662869763806803064     6   \n",
       "47 -8662869763806803064     7   \n",
       "48 -8662869763806803064     8   \n",
       "49 -8662869763806803064     9   \n",
       "50 -8662869763806803064     0   \n",
       "51 -8662869763806803064     1   \n",
       "52 -8662869763806803064     2   \n",
       "53 -8662869763806803064     3   \n",
       "54 -8662869763806803064     4   \n",
       "55 -8662869763806803064     5   \n",
       "56 -8662869763806803064     6   \n",
       "57 -8662869763806803064     7   \n",
       "58 -8662869763806803064     8   \n",
       "59 -8662869763806803064     9   \n",
       "\n",
       "                                      prediction_file      kernel  \\\n",
       "0   -8662869763806803064_Kernel_0_fold_model_polyn...  polynomial   \n",
       "1   -8662869763806803064_Kernel_1_fold_model_polyn...  polynomial   \n",
       "2   -8662869763806803064_Kernel_2_fold_model_polyn...  polynomial   \n",
       "3   -8662869763806803064_Kernel_3_fold_model_polyn...  polynomial   \n",
       "4   -8662869763806803064_Kernel_4_fold_model_polyn...  polynomial   \n",
       "5   -8662869763806803064_Kernel_5_fold_model_polyn...  polynomial   \n",
       "6   -8662869763806803064_Kernel_6_fold_model_polyn...  polynomial   \n",
       "7   -8662869763806803064_Kernel_7_fold_model_polyn...  polynomial   \n",
       "8   -8662869763806803064_Kernel_8_fold_model_polyn...  polynomial   \n",
       "9   -8662869763806803064_Kernel_9_fold_model_polyn...  polynomial   \n",
       "10  -8662869763806803064_Kernel_0_fold_model_polyn...  polynomial   \n",
       "11  -8662869763806803064_Kernel_1_fold_model_polyn...  polynomial   \n",
       "12  -8662869763806803064_Kernel_2_fold_model_polyn...  polynomial   \n",
       "13  -8662869763806803064_Kernel_3_fold_model_polyn...  polynomial   \n",
       "14  -8662869763806803064_Kernel_4_fold_model_polyn...  polynomial   \n",
       "15  -8662869763806803064_Kernel_5_fold_model_polyn...  polynomial   \n",
       "16  -8662869763806803064_Kernel_6_fold_model_polyn...  polynomial   \n",
       "17  -8662869763806803064_Kernel_7_fold_model_polyn...  polynomial   \n",
       "18  -8662869763806803064_Kernel_8_fold_model_polyn...  polynomial   \n",
       "19  -8662869763806803064_Kernel_9_fold_model_polyn...  polynomial   \n",
       "20  -8662869763806803064_Kernel_0_fold_model_polyn...  polynomial   \n",
       "21  -8662869763806803064_Kernel_1_fold_model_polyn...  polynomial   \n",
       "22  -8662869763806803064_Kernel_2_fold_model_polyn...  polynomial   \n",
       "23  -8662869763806803064_Kernel_3_fold_model_polyn...  polynomial   \n",
       "24  -8662869763806803064_Kernel_4_fold_model_polyn...  polynomial   \n",
       "25  -8662869763806803064_Kernel_5_fold_model_polyn...  polynomial   \n",
       "26  -8662869763806803064_Kernel_6_fold_model_polyn...  polynomial   \n",
       "27  -8662869763806803064_Kernel_7_fold_model_polyn...  polynomial   \n",
       "28  -8662869763806803064_Kernel_8_fold_model_polyn...  polynomial   \n",
       "29  -8662869763806803064_Kernel_9_fold_model_polyn...  polynomial   \n",
       "30  -8662869763806803064_Kernel_0_fold_model_polyn...  polynomial   \n",
       "31  -8662869763806803064_Kernel_1_fold_model_polyn...  polynomial   \n",
       "32  -8662869763806803064_Kernel_2_fold_model_polyn...  polynomial   \n",
       "33  -8662869763806803064_Kernel_3_fold_model_polyn...  polynomial   \n",
       "34  -8662869763806803064_Kernel_4_fold_model_polyn...  polynomial   \n",
       "35  -8662869763806803064_Kernel_5_fold_model_polyn...  polynomial   \n",
       "36  -8662869763806803064_Kernel_6_fold_model_polyn...  polynomial   \n",
       "37  -8662869763806803064_Kernel_7_fold_model_polyn...  polynomial   \n",
       "38  -8662869763806803064_Kernel_8_fold_model_polyn...  polynomial   \n",
       "39  -8662869763806803064_Kernel_9_fold_model_polyn...  polynomial   \n",
       "40  -8662869763806803064_Kernel_0_fold_model_polyn...  polynomial   \n",
       "41  -8662869763806803064_Kernel_1_fold_model_polyn...  polynomial   \n",
       "42  -8662869763806803064_Kernel_2_fold_model_polyn...  polynomial   \n",
       "43  -8662869763806803064_Kernel_3_fold_model_polyn...  polynomial   \n",
       "44  -8662869763806803064_Kernel_4_fold_model_polyn...  polynomial   \n",
       "45  -8662869763806803064_Kernel_5_fold_model_polyn...  polynomial   \n",
       "46  -8662869763806803064_Kernel_6_fold_model_polyn...  polynomial   \n",
       "47  -8662869763806803064_Kernel_7_fold_model_polyn...  polynomial   \n",
       "48  -8662869763806803064_Kernel_8_fold_model_polyn...  polynomial   \n",
       "49  -8662869763806803064_Kernel_9_fold_model_polyn...  polynomial   \n",
       "50  -8662869763806803064_Kernel_0_fold_model_polyn...  polynomial   \n",
       "51  -8662869763806803064_Kernel_1_fold_model_polyn...  polynomial   \n",
       "52  -8662869763806803064_Kernel_2_fold_model_polyn...  polynomial   \n",
       "53  -8662869763806803064_Kernel_3_fold_model_polyn...  polynomial   \n",
       "54  -8662869763806803064_Kernel_4_fold_model_polyn...  polynomial   \n",
       "55  -8662869763806803064_Kernel_5_fold_model_polyn...  polynomial   \n",
       "56  -8662869763806803064_Kernel_6_fold_model_polyn...  polynomial   \n",
       "57  -8662869763806803064_Kernel_7_fold_model_polyn...  polynomial   \n",
       "58  -8662869763806803064_Kernel_8_fold_model_polyn...  polynomial   \n",
       "59  -8662869763806803064_Kernel_9_fold_model_polyn...  polynomial   \n",
       "\n",
       "                     loss    Acc      Sens      Spec        SP       AUC  \\\n",
       "0                logistic  0.845  0.792415  0.897796  0.712814  0.845105   \n",
       "1                logistic  0.842  0.794000  0.890000  0.707811  0.842000   \n",
       "2                logistic  0.845  0.818000  0.872000  0.713660  0.845000   \n",
       "3                logistic  0.857  0.810000  0.904000  0.733344  0.857000   \n",
       "4                logistic  0.841  0.816000  0.866000  0.706968  0.841000   \n",
       "5                logistic  0.832  0.792000  0.872000  0.691424  0.832000   \n",
       "6                logistic  0.822  0.768000  0.876000  0.674224  0.822000   \n",
       "7                logistic  0.826  0.776000  0.876000  0.681025  0.826000   \n",
       "8                logistic  0.848  0.816000  0.880000  0.718592  0.848000   \n",
       "9                logistic  0.862  0.814000  0.910000  0.741891  0.862000   \n",
       "10            soft_margin  0.850  0.794411  0.905812  0.721136  0.850111   \n",
       "11            soft_margin  0.857  0.812000  0.902000  0.733436  0.857000   \n",
       "12            soft_margin  0.848  0.826000  0.870000  0.718862  0.848000   \n",
       "13            soft_margin  0.861  0.822000  0.900000  0.740560  0.861000   \n",
       "14            soft_margin  0.847  0.824000  0.870000  0.717144  0.847000   \n",
       "15            soft_margin  0.840  0.802000  0.878000  0.704878  0.840000   \n",
       "16            soft_margin  0.832  0.774000  0.890000  0.690540  0.832000   \n",
       "17            soft_margin  0.834  0.794000  0.874000  0.694756  0.834000   \n",
       "18            soft_margin  0.857  0.828000  0.886000  0.734028  0.857000   \n",
       "19            soft_margin  0.867  0.824000  0.910000  0.750764  0.867000   \n",
       "20  quadratic_soft_margin  0.838  0.768463  0.907816  0.700046  0.838139   \n",
       "21  quadratic_soft_margin  0.840  0.778000  0.902000  0.703675  0.840000   \n",
       "22  quadratic_soft_margin  0.839  0.796000  0.882000  0.702996  0.839000   \n",
       "23  quadratic_soft_margin  0.850  0.792000  0.908000  0.720816  0.850000   \n",
       "24  quadratic_soft_margin  0.839  0.800000  0.878000  0.703160  0.839000   \n",
       "25  quadratic_soft_margin  0.828  0.776000  0.880000  0.684231  0.828000   \n",
       "26  quadratic_soft_margin  0.816  0.744000  0.888000  0.663259  0.816000   \n",
       "27  quadratic_soft_margin  0.822  0.762000  0.882000  0.673882  0.822000   \n",
       "28  quadratic_soft_margin  0.844  0.802000  0.886000  0.711453  0.844000   \n",
       "29  quadratic_soft_margin  0.859  0.802000  0.916000  0.736255  0.859000   \n",
       "30           squared_loss  0.832  0.752495  0.911824  0.689309  0.832159   \n",
       "31           squared_loss  0.837  0.762000  0.912000  0.697751  0.837000   \n",
       "32           squared_loss  0.830  0.784000  0.876000  0.687841  0.830000   \n",
       "33           squared_loss  0.836  0.768000  0.904000  0.696580  0.836000   \n",
       "34           squared_loss  0.823  0.770000  0.876000  0.675923  0.823000   \n",
       "35           squared_loss  0.821  0.752000  0.890000  0.671656  0.821000   \n",
       "36           squared_loss  0.814  0.730000  0.898000  0.659059  0.814000   \n",
       "37           squared_loss  0.820  0.748000  0.892000  0.669803  0.820000   \n",
       "38           squared_loss  0.827  0.774000  0.880000  0.682523  0.827000   \n",
       "39           squared_loss  0.847  0.774000  0.920000  0.714740  0.847000   \n",
       "40          e-insensitive  0.841  0.798403  0.883768  0.706513  0.841085   \n",
       "41          e-insensitive  0.844  0.800000  0.888000  0.711367  0.844000   \n",
       "42          e-insensitive  0.844  0.820000  0.868000  0.712048  0.844000   \n",
       "43          e-insensitive  0.849  0.822000  0.876000  0.720436  0.849000   \n",
       "44          e-insensitive  0.841  0.822000  0.860000  0.707100  0.841000   \n",
       "45          e-insensitive  0.832  0.802000  0.862000  0.691774  0.832000   \n",
       "46          e-insensitive  0.826  0.778000  0.874000  0.681123  0.826000   \n",
       "47          e-insensitive  0.826  0.788000  0.864000  0.681554  0.826000   \n",
       "48          e-insensitive  0.836  0.810000  0.862000  0.698558  0.836000   \n",
       "49          e-insensitive  0.852  0.818000  0.886000  0.725326  0.852000   \n",
       "50                  huber  0.831  0.754491  0.907816  0.687871  0.831153   \n",
       "51                  huber  0.836  0.764000  0.908000  0.696299  0.836000   \n",
       "52                  huber  0.826  0.780000  0.872000  0.681217  0.826000   \n",
       "53                  huber  0.840  0.776000  0.904000  0.703549  0.840000   \n",
       "54                  huber  0.831  0.784000  0.878000  0.689456  0.831000   \n",
       "55                  huber  0.824  0.766000  0.882000  0.677292  0.824000   \n",
       "56                  huber  0.818  0.740000  0.896000  0.666075  0.818000   \n",
       "57                  huber  0.825  0.758000  0.892000  0.678377  0.825000   \n",
       "58                  huber  0.837  0.784000  0.890000  0.699163  0.837000   \n",
       "59                  huber  0.862  0.800000  0.924000  0.741120  0.862000   \n",
       "\n",
       "        Time  \n",
       "0   2.070694  \n",
       "1   2.155312  \n",
       "2   2.155366  \n",
       "3   2.106785  \n",
       "4   2.117187  \n",
       "5   2.006963  \n",
       "6   2.315056  \n",
       "7   2.139889  \n",
       "8   2.125958  \n",
       "9   2.132304  \n",
       "10  0.552664  \n",
       "11  0.596144  \n",
       "12  0.589568  \n",
       "13  0.603745  \n",
       "14  0.558259  \n",
       "15  0.615575  \n",
       "16  0.650401  \n",
       "17  0.629031  \n",
       "18  0.596041  \n",
       "19  0.620196  \n",
       "20  0.614571  \n",
       "21  0.707176  \n",
       "22  0.616575  \n",
       "23  0.744768  \n",
       "24  0.684523  \n",
       "25  0.629297  \n",
       "26  0.626423  \n",
       "27  0.670126  \n",
       "28  0.717402  \n",
       "29  0.730824  \n",
       "30  0.196233  \n",
       "31  0.200484  \n",
       "32  0.195464  \n",
       "33  0.194976  \n",
       "34  0.203062  \n",
       "35  0.191463  \n",
       "36  0.189217  \n",
       "37  0.198853  \n",
       "38  0.189952  \n",
       "39  0.187324  \n",
       "40  1.351387  \n",
       "41  1.352941  \n",
       "42  1.416930  \n",
       "43  1.397757  \n",
       "44  1.438147  \n",
       "45  1.368179  \n",
       "46  1.316453  \n",
       "47  1.348065  \n",
       "48  1.288076  \n",
       "49  1.282007  \n",
       "50  0.663391  \n",
       "51  0.643139  \n",
       "52  0.639191  \n",
       "53  0.543670  \n",
       "54  0.634383  \n",
       "55  0.647208  \n",
       "56  0.640726  \n",
       "57  0.620359  \n",
       "58  0.638821  \n",
       "59  0.635642  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_record = pd.read_csv(os.path.join(model_path,'%s_%s_train_record.csv'%(df_config['hash_id'][train_id], model_type)))\n",
    "train_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c35e7976",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_grouped = train_record[['kernel','loss',\n",
    "                        'Acc','Sens','Spec','SP', 'AUC', 'Time']].groupby(['kernel', 'loss']).mean()\n",
    "std_grouped = train_record[['kernel','loss',\n",
    "                        'Acc','Sens','Spec','SP', 'AUC', 'Time']].groupby(['kernel', 'loss']).std()\n",
    "grouped = pd.concat([mean_grouped,std_grouped],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4c732e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Spec</th>\n",
       "      <th>SP</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">polynomial</th>\n",
       "      <th>e-insensitive</th>\n",
       "      <td>0.839100</td>\n",
       "      <td>0.805840</td>\n",
       "      <td>0.872377</td>\n",
       "      <td>0.703580</td>\n",
       "      <td>0.839109</td>\n",
       "      <td>1.355994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huber</th>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.770649</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.692042</td>\n",
       "      <td>0.833015</td>\n",
       "      <td>0.630653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.884380</td>\n",
       "      <td>0.708175</td>\n",
       "      <td>0.842011</td>\n",
       "      <td>2.132551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quadratic_soft_margin</th>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.782046</td>\n",
       "      <td>0.892982</td>\n",
       "      <td>0.699977</td>\n",
       "      <td>0.837514</td>\n",
       "      <td>0.674169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_margin</th>\n",
       "      <td>0.849300</td>\n",
       "      <td>0.810041</td>\n",
       "      <td>0.888581</td>\n",
       "      <td>0.720610</td>\n",
       "      <td>0.849311</td>\n",
       "      <td>0.601162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squared_loss</th>\n",
       "      <td>0.828700</td>\n",
       "      <td>0.761450</td>\n",
       "      <td>0.895982</td>\n",
       "      <td>0.684518</td>\n",
       "      <td>0.828716</td>\n",
       "      <td>0.194703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e-insensitive</th>\n",
       "      <td>0.008962</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.015145</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>0.051746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huber</th>\n",
       "      <td>0.012211</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.020628</td>\n",
       "      <td>0.012208</td>\n",
       "      <td>0.032410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.012632</td>\n",
       "      <td>0.017914</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.078133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quadratic_soft_margin</th>\n",
       "      <td>0.012756</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.021582</td>\n",
       "      <td>0.012757</td>\n",
       "      <td>0.049932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_margin</th>\n",
       "      <td>0.011528</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>0.019685</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>0.030104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squared_loss</th>\n",
       "      <td>0.009753</td>\n",
       "      <td>0.015914</td>\n",
       "      <td>0.015841</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>0.009759</td>\n",
       "      <td>0.005176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Acc      Sens      Spec        SP  \\\n",
       "kernel     loss                                                            \n",
       "polynomial e-insensitive          0.839100  0.805840  0.872377  0.703580   \n",
       "           huber                  0.833000  0.770649  0.895382  0.692042   \n",
       "           logistic               0.842000  0.799642  0.884380  0.708175   \n",
       "           quadratic_soft_margin  0.837500  0.782046  0.892982  0.699977   \n",
       "           soft_margin            0.849300  0.810041  0.888581  0.720610   \n",
       "           squared_loss           0.828700  0.761450  0.895982  0.684518   \n",
       "           e-insensitive          0.008962  0.015222  0.010714  0.015145   \n",
       "           huber                  0.012211  0.017513  0.015902  0.020628   \n",
       "           logistic               0.012632  0.017914  0.015118  0.021350   \n",
       "           quadratic_soft_margin  0.012756  0.019718  0.014002  0.021582   \n",
       "           soft_margin            0.011528  0.018193  0.015238  0.019685   \n",
       "           squared_loss           0.009753  0.015914  0.015841  0.016248   \n",
       "\n",
       "                                       AUC      Time  \n",
       "kernel     loss                                       \n",
       "polynomial e-insensitive          0.839109  1.355994  \n",
       "           huber                  0.833015  0.630653  \n",
       "           logistic               0.842011  2.132551  \n",
       "           quadratic_soft_margin  0.837514  0.674169  \n",
       "           soft_margin            0.849311  0.601162  \n",
       "           squared_loss           0.828716  0.194703  \n",
       "           e-insensitive          0.008964  0.051746  \n",
       "           huber                  0.012208  0.032410  \n",
       "           logistic               0.012634  0.078133  \n",
       "           quadratic_soft_margin  0.012757  0.049932  \n",
       "           soft_margin            0.011529  0.030104  \n",
       "           squared_loss           0.009759  0.005176  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c554186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criteria</th>\n",
       "      <th>kernel</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spec</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>soft_margin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criteria      kernel         loss\n",
       "0     Spec  polynomial  soft_margin"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_hyperparameters = {'criteria':['Spec'],'kernel':['polynomial'],'loss':['soft_margin']}\n",
    "df_choose_hyperparameters = pd.DataFrame(data=choose_hyperparameters)\n",
    "df_choose_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "645c05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_choose_hyperparameters.to_csv(os.path.join(model_path,'%s_%s_choose_hyperparameters.csv'%(df_config['hash_id'][train_id], model_type)),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0d728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
